import torch
import torch.nn as nn
from torch.utils.data import DataLoader
import torchvision.utils as vutils
import matplotlib.pyplot as plt
from tqdm import tqdm
import os
import glob
from datetime import datetime
from config import Config
from dataset import get_dataloaders
from model import get_model
from utils import calculate_psnr, print_gpu_info, seed_everything

"""
Explanation of Outputs and Images
================================

1. test_results_finetune_noise{noise_std}.png
--------------------------------------------
- Generated By: This script (test_finetune.py), called from main.py.
- Content:
  - Displays 4 test images in a 4x2 grid (row-wise for each image):
    - Column 1: Input (Y, BUSI images, singly-noisy, treated as pseudo-clean).
    - Column 2: Denoised (f(Y) â‰ˆ X, model output from Y).
- Appearance:
  - Input: Moderately grainy, anatomical details visible but noisy.
  - Denoised: Smoother, reduced speckle, clearer structures (e.g., lesion boundaries).
- Interpretation:
  - Good Result:
    - Denoised: Significant noise reduction compared to Input, sharp lesion boundaries, preserved textures. PSNR ~34â€“35 dB.
    - Denoised image is clearer than Input, approaching a hypothetical clean X.
  - Poor Result:
    - Denoised remains noisy (PSNR <32 dB).
    - Blurring or loss of anatomical details (e.g., lesions indistinct).
    - Artifacts like streaks or unnatural textures.
  - Compare to PSNR: PSNR >34 dB indicates effective denoising, but visual quality (sharpness, detail) is critical.

2. finetune_metrics_noise{noise_std}.png
---------------------------------------
- Generated By: finetune.py.
- Content:
  - Two subplots:
    - Left: MSE Loss per Epoch (Train and Validation).
    - Right: PSNR per Epoch (Train and Validation).
- Appearance:
  - Loss Plot: Decreasing curves (e.g., from 0.019 to 0.007) for both train and val.
  - PSNR Plot: Increasing curves (e.g., from 31 dB to 34.5 dB).
- Interpretation:
  - Good Result:
    - Loss decreases steadily, converges to <0.01.
    - PSNR increases, stabilizes at >34 dB.
    - Train and val curves are close (no overfitting).
  - Poor Result:
    - Loss plateaus early or diverges.
    - PSNR remains low (<32 dB).
    - Large gap between train and val (overfitting).

Interpreting Results
===================

Quantitative Metrics
-------------------
- Pretrain:
  - Loss ~0.0100, PSNR ~33.00 dB: Indicates good Noise2Void reconstruction.
  - Good: PSNR >32 dB, loss <0.01.
  - Poor: PSNR <30 dB (model didnâ€™t learn to fill patches).
- Finetune:
  - Denoised (f(Y) vs. Y): Loss ~0.0075, PSNR ~34.80 dB. Shows effective denoising of singly-noisy images.
  - Good: PSNR >34 dB, loss <0.01.
  - Poor: PSNR <32 dB (insufficient denoising).
- Comparison:
  - Fine-tuning PSNR should be higher than pretraining, reflecting improved denoising.
  - Since X is unavailable, PSNR is computed against Y, so focus on visual improvement.

Qualitative Visuals
-------------------
- Pretrain (test_results_pretrain.png):
  - Good: Reconstructed patches match surrounding textures, preserving lesions and tissues.
  - Poor: Blurry patches, mismatched textures, or lost details.
  - Action if Poor: Increase pretrain_epochs, adjust mask_ratio (e.g., 0.2).
- Finetune (test_results_finetune_noise{noise_std}.png):
  - Good:
    - Denoised: Reduced speckle compared to Input, clear anatomical structures.
    - Denoised closer to a hypothetical clean X than Input.
  - Poor:
    - Persistent noise or blurring.
    - Loss of critical details (e.g., lesion edges).
  - Action if Poor:
    - Adjust noise_std (e.g., 0.05 or 0.2).
    - Increase finetune_epochs or lower finetune_lr.
    - Add perceptual loss for sharper outputs.
"""

def get_latest_checkpoint(checkpoint_dir, noise_std):
    """Find the latest checkpoint file matching the noise_std."""
    pattern = os.path.join(checkpoint_dir, f"finetuned_resnet_noise{noise_std}_final_*.pth")
    checkpoint_files = glob.glob(pattern)
    if not checkpoint_files:
        raise FileNotFoundError(f"No checkpoints found matching {pattern}")
    latest_checkpoint = max(checkpoint_files, key=os.path.getmtime)
    return latest_checkpoint

def test_model(model, test_loader, config, checkpoint_path, save_dir="test_outputs_finetune"):
    os.makedirs(save_dir, exist_ok=True)
    if not os.path.exists(checkpoint_path):
        raise FileNotFoundError(f"Checkpoint not found at {checkpoint_path}")
    model.load_state_dict(torch.load(checkpoint_path, map_location=config.device))
    print(f"âœ… Loaded weights from {checkpoint_path}")

    model.eval()
    loss_fn = nn.MSELoss()
    test_loss = 0.0
    test_psnr = 0.0
    num_batches = len(test_loader)
    input_images, denoised_images = [], []

    with torch.no_grad():
        for i, (doubly_noisy, singly_noisy) in enumerate(tqdm(test_loader, desc="Testing Finetuned")):
            singly_noisy = singly_noisy.to(config.device)

            # Test with singly-noisy input: f(Y) â‰ˆ X
            output = model(singly_noisy)
            loss = loss_fn(output, singly_noisy)  # Compare f(Y) to Y (pseudo-clean)
            test_loss += loss.item()
            psnr = calculate_psnr(loss).item()
            test_psnr += psnr

            if i == 0:
                input_images = singly_noisy[:4].cpu()
                denoised_images = output[:4].cpu()

    avg_test_loss = test_loss / num_batches
    avg_test_psnr = test_psnr / num_batches

    print(f"ðŸ“Š Finetuned Test Results (Input Y, Noise Std={config.noise_std}):")
    print(f"Average Test Loss: {avg_test_loss:.4f}")
    print(f"Average Test PSNR: {avg_test_psnr:.2f} dB")

    visualize_results(input_images, denoised_images, config.output_dir, config.noise_std)

def visualize_results(input_images, denoised_images, output_dir, noise_std):
    # Denormalize images
    input_images = input_images * 0.5 + 0.5
    denoised_images = denoised_images * 0.5 + 0.5

    num_images = input_images.size(0)  # 4 images
    plt.figure(figsize=(6, 12))

    # Plot each image's results in a single row
    for i in range(num_images):
        # Input (Singly-Noisy)
        plt.subplot(num_images, 2, i * 2 + 1)
        plt.imshow(input_images[i].squeeze(), cmap='gray')
        plt.title(f"Image {i+1}\nInput")
        plt.axis('off')

        # Denoised
        plt.subplot(num_images, 2, i * 2 + 2)
        plt.imshow(denoised_images[i].squeeze(), cmap='gray')
        plt.title(f"Image {i+1}\nDenoised")
        plt.axis('off')

    plt.tight_layout()
    save_path = os.path.join(output_dir, f"test_results_finetune_noise{noise_std}.png")
    plt.savefig(save_path)
    plt.show()
    print(f"ðŸ“¸ Saved visualization to {save_path}")

    # Save as output.png (assuming this is the intended file)
    output_save_path = os.path.join(output_dir, "output.png")
    plt.savefig(output_save_path)
    print(f"ðŸ“¸ Saved visualization as {output_save_path}")

def main():
    print(f"ðŸ•’ Run started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print_gpu_info()
    seed_everything(42)

    # Create timestamped output directory
    timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
    output_dir = os.path.join("./outs", timestamp)
    os.makedirs(output_dir, exist_ok=True)

    config = Config()
    config.output_dir = output_dir  # Store output_dir in config for visualize_results
    _, _, test_loader = get_dataloaders(config, mode='finetune')
    print(f"ðŸ§ª Testing on {len(test_loader.dataset)} test images")
    model = get_model(model_name="resnet", pretrained=False).to(config.device)
    checkpoint_path = get_latest_checkpoint(config.checkpoint_dir, config.noise_std)
    test_model(model, test_loader, config, checkpoint_path)

if __name__ == "__main__":
    main()